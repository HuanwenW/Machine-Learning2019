## 1.机器学习的一些概念
- ### 有监督学习
   有监督学习是从**标签化**训练数据集中推断出函数的机器学习任务。

> **定义：** 训练数据由一组训练实例组成。在监督学习中，每一个例子都是一对由一个输入对象（通常是一个向量）和一个期望的
> 输出值（也被称为监督信号）。有监督学习算法分析训练数据，并产生一个推断的功能，它可以用于映射新的例子。一个最佳的方案
> 将允许该算法正确地在标签不可见的情况下确定类标签。

   **常用的有监督学习算法：**
 支持向量机 、朴素贝叶斯 、决策树 、K近邻 、线性回归 、逻辑回归 、线性判别分析 
- ### 无监督学习
   无监督学习是指在**没有类别信息**情况下，通过对所研究对象的大量样本的数据分析实现对样本分类的一种数据处理方法。
   
> 现实生活中常常会有这样的问题：缺乏足够的先验知识，因此难以人工标注类别或进行人工类别标注的成本太高。很自然地，
> 我们希望计算机能代我们完成这些工作，或至少提供一些帮助。根据类别未知(没有被标记)的训练样本解决模式识别中的各种
> 问题，称之为无监督学习。它与监督训练的不同之处，在于我们事先没有任何训练样本，而需要直接对数据进行建模。

   **常用的无监督学习算法：**
   主成分分析方法PCA 、聚类 、局部线性嵌入方法 、拉普拉斯特征映射方法 、黑塞局部线性嵌入方法 
- ### 泛化能力
> **定义：** 泛化能力是指机器学习算法对新鲜样本的适应能力。学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集
> 以外的数据，经过训练的网络也能给出合适的输出，该能力称为泛化能力。  
> **性质：** 通常期望经训练样本训练的网络具有较强的泛化能力，也就是对新输入给出合理响应的能力。
- ### 过拟合欠拟合（方差和偏差以及各自解决办法）
**过拟合(over-fitting)** 其实就是所建的机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在验证数据集以及测试数据集中表现不佳。  
**欠拟合（under-fitting）** 由于被提取的特征比较少，导致训练出来的模型不能很好地匹配，表现得很差，导致在验证数据集以及测试数据集中表现不佳。
 #### 解决方案：[过拟合&&欠拟合](https://blog.csdn.net/qq_18254385/article/details/78428887)
- ### [交叉验证](https://www.jianshu.com/p/201a164e1b35)
> **定义：** 交叉验证是一种统计学上将数据样本切割成较小子集的实用方法。其基本思想是把在某种意义下将原始数据,另一部分做为验证集,首先用训练集
> 对分类器进行训练,再利用验证集来测试训练得到的模型,以此来做为评价分类器的性能指标。
## 2.线性回归的原理
**定义：** 线性回归在假设特证满足线性关系，根据给定的训练数据训练一个模型，并用此模型进行预测。
## 3.[线性回归的损失函数代价函数目标函数](https://blog.csdn.net/lyl771857509/article/details/79428475)
1. 损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。
2. 代价函数（Cost Function ）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。
3. 目标函数（Object Function）定义为：最终需要优化的函数。等于经验风险+结构风险（也就是Cost Function + 正则化项）。

## 4.优化方法
- [梯度下降法](https://www.jianshu.com/p/c7e642877b0e)
- [牛顿法](https://blog.csdn.net/ccnt_2012/article/details/81837154)
- [拟牛顿法](https://blog.csdn.net/chunyun0716/article/details/54999799)
## 5.[线性回归的评估指标](https://blog.csdn.net/faithmy509/article/details/81217417)

## 6.sklearn参数详解
clf是不同的分类器，可以是任何的分类器。比如支持向量机分类器。clf = svm.SVC(kernel=’linear’, C=1)   
cv参数就是代表不同的cross validation的方法了。如果cv是一个int数字的话，并且如果提供了raw target参数，那么就代表使用StratifiedKFold分类方式，如果没有提供raw target参数，那么就代表使用KFold分类方式。   
cross_val_score函数的返回值就是对于每次不同的的划分raw data时，在test data上得到的分类的准确率。至于准确率的算法可以通过score_func参数指定，如果不指定的话，是用clf默认自带的准确率算法。

### 参考资料
1. 周志华《机器学习》西瓜书
2. 李航《统计学》
3. 博客：[过拟合&&欠拟合](https://blog.csdn.net/qq_18254385/article/details/78428887)
